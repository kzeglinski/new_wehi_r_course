---
filters:
  - naquiz
format:
  html:
    toc: true
    toc-location: left
    toc-title: "In this chapter:"
---

# RNA-seq - Part 1 {#sec-chapter06}

```{r, include=FALSE}
library(magrittr)
library(knitr)
library(kableExtra)
options(readr.show_col_types = FALSE)
```

In this chapter we will run through the basic steps for analysing a simple RNA-seq experiment using the [limma-voom workflow](https://f1000research.com/articles/5-1408). This includes:

- filtering out lowly expressed genes
- normalisation
- creating a multidimensional scaling (MDS) plot
- creating a design matrix
- fitting gene-wise linear models (with empirical Bayes moderation to more accurately estimate gene-wise variability)
- performing statistical testing for differential expression

Compared to the original article linked above, this workflow has been modified for simplicity but retains all the crucial steps and concepts.

The aim of this chapter is to give you experience with a real-world RNA-seq analysis, and making extensive use of an external library. We will not cover the statistics in any depth. Instead, the goal is to understand how to construct data structures required for specific packages and how to use the functions in those packages to perform the analysis.

Much of the materials here are explained in greater detail in the limma user's guide. You can view this by typing `help("limma")` and following the links.

::: {.callout-tip title="Learning Objectives"}
- Constructing a `DGEList` object to use with the `edgeR` package
- Performing filtering of lowly expressed genes
- Normalising RNA-seq data to account for library size and RNA composition
- Performing exploratory data analysis using MDS plots
- Pulling data out of `edgeR` package objects and re-organising it into a tidy format for use with `ggplot2`.
:::

## Data files

We will work with a counts matrix similar to that generated by Subread [featureCounts](https://subread.sourceforge.net/featureCounts.html), and an Entrez gene annotation file.

{{< downloadthis data/rnaseq_counts.tsv dname=rnaseq_counts label="Download RNAseq counts" icon=file-earmark-arrow-down type=primary class=data-button id=workshop_data >}}

{{< downloadthis data/Ses3_geneAnnot.tsv dname=Ses3_geneAnnot label="Download mouse gene annotations" icon=file-earmark-arrow-down type=primary class=data-button id=workshop_data >}}

Save these files in the `data/` directory within your R project parent directory.

## R Packages

Let's load edgeR (Estimating Digital Gene Expression in R), which also loads the limma package. We also load the tidyverse packages, which will be used to extract and plot data from the edgeR and limma objects.
```{r}
#| message: false
#| warning: false

library(edgeR)
library(tidyverse)

```

If you get an error, the package can be downloaded by the following commands. 
```{r}
#| message: false
#| warning: false
#| eval: false

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("edgeR")
```

## Loading in read count data and annotation

The data we are looking at comes from three cell populations (basal, luminal progenitor (LP) and mature luminal (ML)) sorted from the mammary glands of female virgin mice, each profiled in triplicate. These samples have been sequenced using Illumina RNAseq platforms and we will be using the `edgeR` package to analyse the data.

Let's read in the raw counts and gene annotation data:

```{r}
counts_tbl <- read_tsv('data/rnaseq_counts.tsv')

gene_anno <- read_tsv('data/Ses3_geneAnnot.tsv')
```




## Creating the DGEList object


To use the `edgeR` package we first need to construct a `DGEList` object. This object contains 3 key pieces of data:

- `counts`: the main data of this object, a matrix of count values with samples along the columns and features/genes along the rows. All data must be numeric!
- `samples`: a data frame containing annotation for the samples. The rows in this table describe the corresponding column of the counts data. `samples` is created automatically by the `DGEList()` function.
- `genes`: a data frame containing annotation for the genes in the counts matrix. The rows in this table describe the corresponding row in the counts matrix. Importantly, the row order for `counts` and `genes` must be identical for your analysis to run as expected!

::: {.callout-note title="Data objects"}

Data objects in general are a way to store related pieces of information together. Often they provide features to maintain the relationships between the pieces of information. For example, in a `DGEList` object, the `counts` are stored as a matrix while `samples` and `genes` are stored as data frames. When you subset the `DGEList` object, the rows and columns of the `counts` matrix are subset along with the corresponding rows of the `samples` and `genes` data frames. This prevents errors that can occur if the user tries to manually subset all three pieces of information separately.

:::

A common way to create a `DGEList` object is to read in the count data as a matrix or data frame, and then create the `DGEList` object using the `DGEList()` function. 

::: .callout-info
What you can do with data objects is determined by package that the object comes from. You will need to read the package documentation to find out how to access data from the object. Here `edgeR` informs us that the `DGEList` has data that can be accessed as if it was a list.
:::

DGEList converts numeric data into matrix format for the counts element.

```{r}
dge <- DGEList(counts = counts_tbl %>% select(-1),
               genes = gene_anno)
```

The samples table is automatically created based on information in counts
```{r}
dge$samples
```
We have the library size (column sums for counts matrix) pre-computed. Note that the experimental group has not yet been defined. To do this we first create a text vector encoded as a factor.


### A brief detour to factors


According to the original experimental description, the counts in each column are either from basal, luminal progenitor (LP) or mature luminal (ML) cell populations. The exact experimental groups are as follows
```{r}
groups <- c("LP", "ML", "Basal", "Basal", "ML", "LP", "Basal", "ML", "LP")

groups <- parse_factor(groups,  levels = c("Basal", "LP", "ML"))

```


Note that when we declared the `groups` variable, we used factors. Factors are a special data type that is used to encode categorical variables. They have multiple useful properties in comparison to regular character vectors:
- They allow you to specify the order of the levels.
- They are stored as integers but displayed as labels.
- They encode all the valid levels of the factor, even if they are not present in the data.

Specifying the order of the levels is useful because it allows you to re-arrange labels when used in plots. In this data we would have the "Basal" group first, followed by "LP" and then "ML". Using `parse_factor()` also allows you to check that the values are all valid levels, for example if one of the samples was labelled "Bassal" instead of "Basal", it would throw an error. You can read the R for Data Science [chapter on factors](https://r4ds.had.co.nz/factors.html) for more information, as well as the [forcats package](https://forcats.tidyverse.org) for many useful functions for working with factors.

## Finalising the DGEList object

To specify the experimental groups, we can update the `group` column in the `samples` table as follows:
```{r}
dge$samples$group <- groups
```

Lastly we can set the rownames (a text vector) for the `counts` and `genes` tables, which is useful to avoid losing information downstream.

```{r}
rownames(dge$counts) <-  counts_tbl %>% pull(ENTREZID)

rownames(dge$genes) <-  gene_anno %>% pull(ENTREZID)

head(dge$counts)

head(dge$genes)

```


Now we have a data object that can be used for downstream analysis.


## Filtering

The first step of our analysis is to filter out lowly expressed genes. There are two main problems with low abundant genes:

- Technical variation is more problematic for low abundance genes. This variation is thought to be due to two factors; insufficient mixing and low sampling fraction [@mcintyre2011].
  - Insufficient mixing of solutions during library preparation can result in uneven distribution of reads.
  - RNA sequencing can be thought of as sampling. Measurement errors will occur simply due to the random nature of the sampling process. This problem affects lowly abundant RNA species more because the relative error for small count values is larger than it would be for more highly abundant RNA species.
- Genes that are very lowly expressed do not produce sufficient information to be useful for biological interpretation. For example, it is very hard to believe the biological significance of genes that have counts ranging from 0 to 3 across samples even if come up as statistically significant.

Removing these highly variable, lowly expressed genes increases your 'power' to detect differentially expressed genes [@bourgon2010], where 'power' is your ability to detect true positives. In testing for differential expression, a statistical test is conducted for each gene. When a high number of statistical tests are performed, a portion of them will be significant purely due to random chance. A common procedure to control for the number of false positive is to perform 'multiple testing correction' on the p-values. This adjusts the p-value in a way that reduces the number of false positives but comes at the cost of reduced power to detect true positives. If we filter out uninteresting, lowly expressed genes, we need to perform fewer statistical tests and reduce the impact that multiple testing adjustment has on detection power.

The `edgeR` provides the `filterByExpr()` function to automate gene filtering. By default, it aims to keep genes with a count of 10 or more, in at least as many samples as the smallest experimental group. In our experiment, there are 3 phenotype groups each with 3 samples. Therefore we retain only genes that have 10 or more counts in 3 or more samples. The actual filtering is done on counts per million, prevent bias against samples with small library sizes. This complex procedure is the reason why the package provides a function to perform the filtering for you.

The output of this function is a vector of logicals, indicating which genes (rows) should be kept and which filtered.

Its good practice to create a new DGEList for each step of the filtering and normalization process, to allow easy before-and-after comparisons. We create `dge_filt` here:
```{r}
keep <- filterByExpr(dge)
table(keep)
proportions(table(keep))

dge_filt <- dge[keep, , keep.lib.sizes = FALSE]

```
Compare the effect of filtering out lowly-expressed genes on the data dimensions
```{r}
dim(dge)
dim(dge_filt)
```


We can see that we now have 16624 genes. We started with 27179 genes - meaning that ~40% of genes have been filtered out.

## Library-size normalisation

After filtering, our next step is to normalise the data. Normalisation refers to the process of adjusting the data to reduce or eliminate systematic bias. This allows the data to be meaningfully compared across samples or experimental groups.

There are two main factors that need to be normalised for in RNA-seq:

- Sequencing depth/library size - technically, sequencing a sample to half the depth will give, on average, half the number of reads mapping to each gene [@robinson2010].
- RNA composition - if a large number of genes are unique to, or highly expressed in, only one experimental condition, the sequencing capacity available for the remaining genes in that sample is decreased. For example, if there are only five genes being studied in two experimental groups, if one gene is particularly high in group A, then with limited sequencing depth, that gene will reduce the counts of the remaining four genes. The effect of this is that the remaining four genes appear under-expressed in group A compared to group B when the true amount of gene product is actually equal for these 4 genes [@robinson2010].

Sequencing depth is accounted for by calculating the counts per million (cpm). This metric is calculated by:

1.  taking the library size (sum of all counts for a sample),
2.  dividing this by 1,000,000 to get the 'per million' scaling factor,
3.  then dividing all read counts for each gene in that sample by the 'per million' scaling factor

RNA composition can be accounted for by using more sophisticated normalisation methodologies. We will use 'trimmed mean of M-values' (TMM), which estimates relative RNA levels from RNA-seq data [@robinson2010]. Under the assumption that most genes are not differentially expressed, TMM calculates a library size scaling factor for each library (sample). This is done using the following steps:

1.  calculate the gene expression log fold changes and absolute expression values for pair-wise samples (selecting one sample from the experiment as a reference)
2.  remove the genes with the highest and lowest fold changes and absolute expression values
3.  take a weighted mean of the remaining genes (where the weight is the inverse of the approximate asymptotic variances). This gives the normalisation factor for each library (sample)

Subsequent steps in this analysis will use log-cpm values, calculated using the normalisation factors, which scales each library size.

We can calculate the normalisation factors, specifying that we want to use the `"TMM"` method. We now create `dge_norm` from `dge_filt`.

```{r}
dge_norm <- calcNormFactors(dge_filt, method = "TMM")
```

This function calculates the normalisation factors for each library (sample) and puts this information in the `samples` data frame. Note that it takes dge (our `DGEList` object as input) and returns a `DGEList` object as well.

Let's take a look at our normalisation factors:

```{r}
dge_norm$samples
```

These normalisation factors are all close to 1 for all samples, suggesting minimal difference in RNA composition between samples.

## Extracting tidy tables

For ease of tidy data manipulation and plotting, at this point let's extract tidy tables from the tables nested within the DGEList!

```{r}


samples_tbl <- dge_norm$samples %>% as_tibble(rownames = 'id')

counts_raw_tbl  <- dge$counts %>% as_tibble(rownames='gene')

counts_filt_tbl <- dge_filt$counts %>% as_tibble(rownames='gene') 

```



## Visualising the effect of normalisation

To visualise the effect of TMM normalisation, we can plot the log-counts as a boxplot, and observe the effect of applying the normalisation. To create a boxplot of the log-counts, we can use `log(dge$counts + 0.5)` to create the log-count matrix. The addition of 0.5 is to avoid taking the log of zero. Then in order to use `ggplot2` for plotting, we must convert the matrix to a data frame. We can use the `as_tibble(rownames = "gene")` function to convert the matrix to a data frame where the rownames are converted to a column called "gene". We can then use the `pivot_longer()` function to convert the data frame from wide format to long format, where each row represents a single observation. This is necessary for `ggplot2` to plot the data correctly.

```{r}

counts_raw_tbl %>% 
  pivot_longer(cols = -gene,
               names_to = "sample", values_to = "counts"
  ) %>% 
  mutate(log_counts  = log10(counts + 0.5)) %>% 
  ggplot(aes(x = sample, y = log_counts)) +
  geom_boxplot() +
  ggtitle('Log-transformed raw counts, before filtering')


counts_filt_tbl %>% 
   pivot_longer(cols = -gene,
               names_to = "sample", values_to = "counts"
  ) %>% 
  mutate(log_counts  = log10(counts + 0.5)) %>% 
  ggplot(aes(x = sample, y = log_counts)) +
  geom_boxplot() +
  ggtitle('Log-transformed raw counts, after filtering')

```

We can compare this to the cpm values which when calculated using the `cpm()` function, automatically applies normalisation factors if they are present.

```{r}

logcpm_tbl <- cpm(dge_norm$counts, log=T) %>% as_tibble(rownames='gene')

```

```{r}

logcpm_tbl %>% 
  pivot_longer(cols = -gene,
               names_to = "sample", 
               values_to = "log_cpm") %>% 
  ggplot(aes(x = sample, y = log_cpm)) +
  geom_boxplot() +
  ggtitle('Expression normalized by lib size [CPM] and complexity [TMM]')

```

We see that by performing normalisation on our data, the gene expression values of each sample now have similar medians and quantiles. This indicates that the relative expression values of each sample can be more meaningfully compared.

## MDS plots

Before we perform statistical tests, it's useful to perform some exploratory visual analysis to get an overall idea of how our data is behaving.

MDS is a way to visualise distances between sets of data points (samples in our case). It is a dimensionality reduction technique, similar to principal components analysis (PCA). We treat gene expression in samples as if they were coordinates in a high-dimensional coordinate system, then we can find "distances" between samples as we do between points in space. Then the goal of the algorithm is to find a representation in lower dimensional space such that points that the distance of two objects from each other in high dimensional space is preserved in lower dimensions.

The `plotMDS()` from `limma` creates an MDS plot from a `DGEList` object.

```{r}
plotMDS(dge_norm)
```

Each point on the plot represents one sample and is 'labelled' using the sample name. The distances between each sample in the resulting plot can be interpreted as the typical log2-fold-change between the samples, for the most differentially expressed genes.

We can change the labelling to use the name of the group the sample belongs to instead:

```{r}
plotMDS(dge_norm, labels = groups)
```

This shows us that the phenotype groups tend to cluster together, meaning that the gene expression profiles are similar for samples within a phenotype group. The 'Basal' type samples quite close together while the 'LP' (luminal progenitor) and 'ML' (mature luminal) type samples are further apart, signifying that their expression profiles are more variable.

## MDS plot using ggplot2

For more customisability and better consistency with the style of other plots, it'd be nice to be able to draw the MDS plot using `ggplot2`. In order to do this we would need the MDS coordinates calculated by `plotMDS()`. Luckily the documentation of `plotMDS()` shows that it returns multiple computed values.

```{r}
mds_result <- plotMDS(dge_norm, plot = FALSE)
mds_result
```

We see that there's are `x` and `y` values in the list returned by the `plotMDS()` function, we can put these into a table and see if they match up to the positions plotted by the function.

```{r}
mds_tbl <- tibble(
  id = samples_tbl %>% pull(id),
  dim1 = mds_result$x,
  dim2 = mds_result$y
) %>% print()

ggplot(mds_tbl, aes(x = dim1, y = dim2)) +
  geom_point()
```

The positions of the points and the range of the scales seem to match, so we want to add in more metadata to help use plot. We can try to recreate the MDS plot using just `ggplot2`.

First we extract the transcriptional variance explained by each dimension into a tibble, and add a column defining the dimensions.

```{r}

var_expln <- tibble(propn = mds_result$var.explained * 100 ) %>% 
    rownames_to_column(var = 'dimension') 
```

Dimensions 1 and 2 are plotted by default. We can now extract and round the proportion of variance explained in rows 1 and 2 of the `var_expln` tibble

```{r}

dim1_expl <- var_expln %>% filter(dimension==1) %>% pull(propn) %>% round()
dim2_expl <- var_expln %>% filter(dimension==2) %>% pull(propn) %>% round()

```

Finally we join the full sample metadata with the MDS coordinates for plotting, using `left_join()`
```{r}

mds_tbl_label <- left_join(samples_tbl, mds_tbl, by = 'id') %>% 
  print()


```
To recreate the plotMDS plot:

```{r}
mds_tbl_label %>% 
  ggplot(aes(x=dim1, y=dim2)) + 
  geom_text(aes(label = group)) + 
  labs(x = paste0('Dim 1 variance explained = ', dim1_expl,'%'),
       y = paste0('Dim 2 variance explained = ', dim2_expl,'%'))

```

Now that we have our data in a nice tidy format we can use with ggplot, it's easy to create variations of the plot. For example we can draw points instead of group labels, and use colour to identify the groups.

```{r}
mds_tbl_label %>% 
  ggplot(aes(x=dim1, y=dim2, colour = group)) + 
  geom_point() + 
  labs(x = paste0('Dim 1 variance explained = ', dim1_expl,'%'),
       y = paste0('Dim 2 variance explained = ', dim2_expl,'%'))

```

Alternatively we can also use the labels to identify the individual samples while colouring them by their group.


```{r}
mds_tbl_label %>% 
  ggplot( aes(x = dim1, y = dim2, col = group)) +
  geom_point() +
  geom_text(aes(label = id)) +
  labs(x = paste0('Dim 1 variance explained = ', dim1_expl,'%'),
       y = paste0('Dim 2 variance explained = ', dim2_expl,'%'))
```


We see that some labels are very hard to read due to the overlapping, so we can use the `ggrepel` package to fix this. The `ggrepel` package creates labels that repel each other in order to avoid overlap. It's a good idea to use it in conjunction with `geom_point()` in order to keep track of exact coordinate of the data point.

```{r}
library(ggrepel)

mds_tbl_label %>% 
  ggplot( aes(x = dim1, y = dim2, col = group)) +
  geom_point() +
  geom_text_repel(aes(label = id)) +
  labs(x = paste0('Dim 1 variance explained = ', dim1_expl,'%'),
       y = paste0('Dim 2 variance explained = ', dim2_expl,'%'))
```

## Summary

Today we started on the early steps of the RNA-seq analysis workflow.

- We learned how to create a `DGEList` object, demonstrating how to create data objects required by specific packages.
- We learned how to use edgeR's `filterByExpr()` function to filter out lowly expressed genes.
- We learned how to normalise the data using TMM normalisation.
- We learned how to create MDS plots using both `plotMDS()` and `ggplot2`.
- We learned how to use `ggrepel` to create non-overlapping labels in `ggplot2` plots.

This provides a good foundation for organising data to satisfy the requirements of specific packages, and how to pull data out of the objects created by those packages. The data we pulled out can then be organised into a tidy format to leverage the power of all the `tidyverse` functions that we have learned so far.

In the next chapter we will continue the RNA-seq analysis workflow and complete our differential expression analysis.

## References
