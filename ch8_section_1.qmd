---
filters:
  - naquiz
format:
  html:
    toc: true
    toc-location: left
    toc-title: "In this section:"
---

# Part 1 {.unnumbered #sec-mlpart01} 

## Setup

```{r setup}
#| include: false
#| fig-width: 12

rm(list=ls());gc()

knitr::opts_chunk$set(fig.width = 10, fig.height=7)
```

```{r}
#| output: false
#| message: false


library(tidyverse)
library(readxl)
library(broom)
library(ggridges)

library(tidyrstats)

theme_set(theme_minimal())

```

## Read data

```{r}

tumor_data <- readxl::read_xlsx('data/tumor_data.xlsx')

tumor_data



```


The data contains `r nrow(tumor_data)` tissue samples which have been imaged in a histology lab, as referenced in this chapter [Background](chapter_8.qmd). Each sample has the anonymized donor id and malignancy status determined by a trained pathologist (benign or malignant).

Automatic quantification of image features produces `r ncol(tumor_data) -2` 'features' including cell shapes, edge (plasma membrane) definition, cytosolic texture, staining intensity, necrosis, vascularity etc.

## Explore the data

### Reshape for plotting

```{r}

dat_long <- tumor_data %>% 
  pivot_longer(names_to = "key", values_to = "value", 
               cols = -c(donorid, status))

```

### Check distributions

```{r}

dat_long %>%   ggplot(aes(x=value,group=key)) + geom_density()

```

The data doesnt look normally distributed, but there is a big over-plotting problem here. Let's use the ggridges package to produce a single density plot for each feature:

```{r}

dat_long %>%  ggplot(aes(x=value)) + 
  geom_density_ridges(aes(y=key))
```

The measurements in the dataset have a positive skew, meaning they are non-normal. For best results in machine learning (and data analysis more generally) its usually best to transform the data into a normal distribution where possible.

### Log transform

```{r}
dat_long_log <- dat_long %>%
  mutate(value=log10(value))
```

Plot transformed data

```{r}

dat_long_log %>%  ggplot(aes(x=value)) + 
  geom_density_ridges(aes(y=key))
```

The data looks more normal now. Note that the mean values are different. This can be addressed by scaling data, which we return to later.

### Cluster analysis

Let's run an unsupervised machine learning method to explore how the samples group together using a 'data-driven' approach. `pr_comp()` gives us principal components analysis, and requires wide-format data.

Reshape log-transformed data to wide format, and calculate principal components using the quantitative features (i.e., everything except donorid and malignancy status).

```{r}

dat_wide_log <- dat_long_log %>% 
  pivot_wider(names_from = "key", values_from="value") 
  
pc_dat <- dat_wide_log %>% select(-c(donorid,status)) %>% 
        #principal components function
  prcomp()

```

We can access the principal components for each sample by using the `broom::augment()` function. The primary PCs (e.g. 1 thru 5) encode the majority of the variation between samples. As such we focus on primary PCs (or dimension in MDS), when clustering samples

Plot first 2 PCs, coloured by tumor status

```{r}

pcs_fitted <- pc_dat %>% augment() 
  
#Join the sample labels to the fitted PCs
pc_plot_dat <- bind_cols(tumor_data %>% select(status), 
                         pcs_fitted) 

#Scatter plot
pc_plot_dat %>% 
  ggplot(aes(.fittedPC1, .fittedPC2)) + 
  geom_point(aes(col=status), size=2)

```

There is certainly not a clear separation between malignant and benign. This indicates we will need to try a more sensitive/advanced method to reliably predict the tissue status.

### Linear model

Lets try one of the simplest ML engines - the linear model, to see whether any of the imaging features are significantly associated with tissue status.

If we define a model where imaging feature is the *outcome* (y) and tumor status is the *predictor* (x) we can test for associations quite easily, using `lm_test()`.

Our experimental question is 'Are any features (y) significantly different between benign (x = 0 ) and malignant (x=1)?'

```{r}

#marginal effects
dat_long_log %>% group_by(key) %>% 
  lm_test( value ~  status  ) %>% filter(term!='intercept') 


```

We can see several features do have significant associations with tissue status! This means that, although those feature associations are not large/strong enough to drive sample separation in PCA, the should be able to be combined to build a good predictive model.

### Confirm LM results graphically

```{r}

#features_of_interest (FOI)
foi <- c('granularity','intensity_8','membrane_curvature')

dat_long_log %>% 
  filter(key %in% foi) %>% 
  ggplot(aes(x=status , y=value)) + geom_boxplot() +
  geom_jitter(aes(group=status), width=0.2,size=0.5) +
  facet_wrap(~key)
```

## Save output

For the next steps, we will save the log-transformed, wide-format data (used for the PC analysis).

```{r}
writexl::write_xlsx(dat_wide_log,
                    'data_processed/tumor_data_log_wide.xlsx')
```
